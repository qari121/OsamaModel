// app-realtime.js â€” Real-time nail AR with performance monitoring

const API_URL = "/api/nails/segment";

// UI Elements
const startBtn = document.getElementById("startBtn");
const segmentBtn = document.getElementById("segmentBtn");
const toggleProcessing = document.getElementById("toggleProcessing");
const colorPicker = document.getElementById("colorPicker");
const intensityEl = document.getElementById("intensity");
const glossinessEl = document.getElementById("glossiness");
const metallicEl = document.getElementById("metallic");
const processingIntervalEl = document.getElementById("processingInterval");

const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const statusDiv = document.getElementById("statusDiv");
const liveIndicator = document.getElementById("liveIndicator");

// Stats UI
const fpsValue = document.getElementById("fpsValue");
const renderTime = document.getElementById("renderTime");
const apiLatency = document.getElementById("apiLatency");
const nailCount = document.getElementById("nailCount");
const frameSize = document.getElementById("frameSize");

// Value displays
const intensityValue = document.getElementById("intensityValue");
const glossValue = document.getElementById("glossValue");
const metallicValue = document.getElementById("metallicValue");
const intervalValue = document.getElementById("intervalValue");

// State
let stream = null;
let nailRenderer = null;
let offscreenCanvas = null;
let offscreenCtx = null;
let currentMaskCanvas = null;
let isProcessing = false;
let processingInterval = null;

// Performance tracking
let frameCount = 0;
let lastFpsUpdate = performance.now();
let lastFrameTime = performance.now();
let renderTimes = [];

console.log("âœ“ Real-time app loaded");

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Event Listeners â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

startBtn.addEventListener("click", startCamera);
segmentBtn.addEventListener("click", segmentOnce);
toggleProcessing.addEventListener("click", toggleRealtimeProcessing);

colorPicker.addEventListener("input", renderFrame);
intensityEl.addEventListener("input", (e) => {
  intensityValue.textContent = e.target.value + "%";
  renderFrame();
});
glossinessEl.addEventListener("input", (e) => {
  glossValue.textContent = e.target.value + "%";
  renderFrame();
});
metallicEl.addEventListener("input", (e) => {
  metallicValue.textContent = e.target.value + "%";
  renderFrame();
});
processingIntervalEl.addEventListener("input", (e) => {
  intervalValue.textContent = e.target.value + "ms";
  if (isProcessing) {
    stopRealtimeProcessing();
    startRealtimeProcessing();
  }
});

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Camera â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function startCamera() {
  console.log("ğŸ¥ Starting camera...");
  setStatus("Requesting camera access...");

  if (!navigator.mediaDevices?.getUserMedia) {
    console.error("âŒ getUserMedia not available");
    setStatus("Camera not available. Use localhost or https.", "error");
    return;
  }

  if (stream) {
    console.log("âš ï¸ Camera already running");
    setStatus("Camera already running.", "success");
    return;
  }

  try {
    console.log("ğŸ“¹ Requesting camera stream...");
    // Lower resolution for better performance
    stream = await navigator.mediaDevices.getUserMedia({
      video: {
        facingMode: "user",
        width: { ideal: 640 },  // Reduced from 1280
        height: { ideal: 480 }  // Reduced from 720
      },
      audio: false
    });

    console.log("âœ… Got camera stream:", stream);
    console.log("Video tracks:", stream.getVideoTracks());

    video.srcObject = stream;
    console.log("ğŸ“º Set video.srcObject");

    // Wait for metadata
    console.log("â³ Waiting for video metadata...");

    // Check if metadata is already loaded (sometimes it loads instantly)
    if (video.videoWidth > 0) {
      console.log("ğŸ“Š Metadata already loaded! (fast path)");
    } else {
      // Wait for loadedmetadata event
      await new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
          reject(new Error("Timeout waiting for video metadata (5s)"));
        }, 5000);

        video.addEventListener("loadedmetadata", () => {
          clearTimeout(timeout);
          console.log("ğŸ“Š Metadata loaded via event!");
          resolve();
        }, { once: true });
      });
    }

    console.log("â–¶ï¸ Ensuring video is playing...");
    try {
      await video.play();
      console.log("âœ… Video.play() succeeded!");
    } catch (playErr) {
      console.warn("âš ï¸ Video.play() failed, but might auto-play:", playErr);
      // Don't throw - autoplay might handle it
    }

    console.log(`ğŸ“ Video dimensions: ${video.videoWidth}Ã—${video.videoHeight}`);

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    frameSize.textContent = `${video.videoWidth}Ã—${video.videoHeight}`;

    // Initialize WebGL
    console.log("ğŸ® Initializing WebGL renderer...");
    nailRenderer = new NailRenderer(canvas);
    console.log("âœ… WebGL renderer created");

    // Create offscreen canvas for mask
    offscreenCanvas = document.createElement("canvas");
    offscreenCanvas.width = canvas.width;
    offscreenCanvas.height = canvas.height;
    offscreenCtx = offscreenCanvas.getContext("2d");
    console.log("âœ… Offscreen canvas created");

    startBtn.disabled = true;
    startBtn.textContent = "âœ“ Camera Running";
    segmentBtn.disabled = false;
    toggleProcessing.disabled = false;
    liveIndicator.style.display = "flex";

    setStatus("Camera started! Click 'Segment Nails' or start real-time processing.", "success");
    console.log("âœ… Camera setup complete!");

    // Start render loop
    console.log("ğŸ”„ Starting render loop...");
    startRenderLoop();

  } catch (err) {
    console.error("âŒ Camera error:", err);
    console.error("Error name:", err.name);
    console.error("Error message:", err.message);
    console.error("Error stack:", err.stack);
    setStatus(`Camera error: ${err.message}`, "error");
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Render Loop (FPS Tracking) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function startRenderLoop() {
  function loop() {
    const now = performance.now();
    const delta = now - lastFrameTime;
    lastFrameTime = now;

    // Update FPS counter
    frameCount++;
    if (now - lastFpsUpdate >= 1000) {
      const fps = Math.round(frameCount * 1000 / (now - lastFpsUpdate));
      fpsValue.textContent = fps;
      frameCount = 0;
      lastFpsUpdate = now;
    }

    // Render frame
    const renderStart = performance.now();
    renderFrame();
    const renderDuration = performance.now() - renderStart;

    // Track render time (moving average)
    renderTimes.push(renderDuration);
    if (renderTimes.length > 30) renderTimes.shift();
    const avgRenderTime = renderTimes.reduce((a, b) => a + b, 0) / renderTimes.length;
    renderTime.textContent = avgRenderTime.toFixed(1) + "ms";

    requestAnimationFrame(loop);
  }
  loop();
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Rendering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function renderFrame() {
  if (!nailRenderer || !video.readyState || video.paused) return;

  // Capture video frame
  const tempCanvas = document.createElement("canvas");
  tempCanvas.width = canvas.width;
  tempCanvas.height = canvas.height;
  const tempCtx = tempCanvas.getContext("2d");
  tempCtx.drawImage(video, 0, 0);
  const videoImageData = tempCtx.getImageData(0, 0, canvas.width, canvas.height);

  // Update video texture
  nailRenderer.updateVideoTexture(videoImageData);

  // Update mask texture (if we have one)
  if (currentMaskCanvas) {
    nailRenderer.updateMaskTexture(currentMaskCanvas);
  } else {
    // No mask yet - create empty mask
    offscreenCtx.clearRect(0, 0, canvas.width, canvas.height);
    nailRenderer.updateMaskTexture(offscreenCanvas);
  }

  // Get parameters
  const polishColor = hexToRgbNormalized(colorPicker.value);
  const intensity = parseInt(intensityEl.value) / 100.0;
  const glossiness = parseInt(glossinessEl.value) / 100.0;
  const metallic = parseInt(metallicEl.value) / 100.0;

  // Render with WebGL
  nailRenderer.render(polishColor, intensity, glossiness, metallic);
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Segmentation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function segmentOnce() {
  if (!video.videoWidth) {
    setStatus("Camera not ready", "error");
    return;
  }

  segmentBtn.disabled = true;
  segmentBtn.textContent = "â³ Processing...";

  await performSegmentation();

  segmentBtn.disabled = false;
  segmentBtn.textContent = "ğŸ” Segment Nails";
}

async function performSegmentation() {
  const apiStart = performance.now();

  try {
    console.log("ğŸ“¸ Capturing frame for segmentation...");

    // Capture frame
    const tempCanvas = document.createElement("canvas");
    tempCanvas.width = video.videoWidth;
    tempCanvas.height = video.videoHeight;
    const tempCtx = tempCanvas.getContext("2d");
    tempCtx.drawImage(video, 0, 0);

    console.log(`Frame size: ${tempCanvas.width}Ã—${tempCanvas.height}`);

    // Send to API - lower quality for faster upload
    const blob = await canvasToBlob(tempCanvas, "image/jpeg", 0.6);  // Reduced from 0.85
    console.log(`Blob size: ${(blob.size / 1024).toFixed(1)}KB`);

    const formData = new FormData();
    formData.append("file", blob, "frame.jpg");

    console.log(`ğŸŒ Sending to API: ${API_URL}`);

    const response = await fetch(API_URL, {
      method: "POST",
      body: formData
    });

    const apiEnd = performance.now();
    const latency = Math.round(apiEnd - apiStart);
    apiLatency.textContent = latency + "ms";

    console.log(`ğŸ“¡ Response status: ${response.status} (${latency}ms)`);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("API error response:", errorText);
      throw new Error(`API error ${response.status}: ${errorText.substring(0, 100)}`);
    }

    const data = await response.json();
    console.log("âœ… Segmentation result:", data);

    if (!data.nails || data.nails.length === 0) {
      setStatus("No nails detected. Try better lighting or move closer.", "error");
      nailCount.textContent = "0";
      currentMaskCanvas = null;
      return;
    }

    // Build mask
    buildMask(data.nails);
    nailCount.textContent = data.nails.length.toString();

    setStatus(`âœ“ Detected ${data.nails.length} nails (${latency}ms latency)`, "success");

  } catch (err) {
    console.error("âŒ Segmentation error:", err);
    console.error("Error stack:", err.stack);
    setStatus(`Segmentation failed: ${err.message}`, "error");
    apiLatency.textContent = "Error";
  }
}

function buildMask(nails) {
  const w = offscreenCanvas.width;
  const h = offscreenCanvas.height;

  offscreenCtx.clearRect(0, 0, w, h);
  offscreenCtx.fillStyle = "white";

  // Draw all nail polygons
  for (const nail of nails) {
    const poly = nail.polygon;
    if (!poly || poly.length < 6) continue;

    offscreenCtx.beginPath();
    offscreenCtx.moveTo(poly[0], poly[1]);
    for (let i = 2; i < poly.length; i += 2) {
      offscreenCtx.lineTo(poly[i], poly[i + 1]);
    }
    offscreenCtx.closePath();
    offscreenCtx.fill();
  }

  // Apply blur for smooth edges
  offscreenCtx.filter = "blur(3px)";
  offscreenCtx.drawImage(offscreenCanvas, 0, 0);
  offscreenCtx.filter = "none";

  currentMaskCanvas = offscreenCanvas;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Real-Time Processing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function toggleRealtimeProcessing() {
  if (isProcessing) {
    stopRealtimeProcessing();
  } else {
    startRealtimeProcessing();
  }
}

function startRealtimeProcessing() {
  if (isProcessing) return;

  const interval = parseInt(processingIntervalEl.value);

  isProcessing = true;
  toggleProcessing.textContent = "â¸ Stop Real-Time";
  toggleProcessing.classList.remove("secondary");
  toggleProcessing.classList.add("primary");
  setStatus(`Real-time processing active (every ${interval}ms)`, "success");

  let isSegmenting = false;

  // Run segmentation at intervals - but skip if previous one is still running
  processingInterval = setInterval(async () => {
    if (!isSegmenting && !segmentBtn.disabled) {
      isSegmenting = true;
      try {
        await performSegmentation();
      } finally {
        isSegmenting = false;
      }
    } else {
      console.log("â­ï¸ Skipping segmentation (previous still running)");
    }
  }, interval);

  // Do first segmentation immediately
  performSegmentation();
}

function stopRealtimeProcessing() {
  if (!isProcessing) return;

  isProcessing = false;
  clearInterval(processingInterval);
  processingInterval = null;

  toggleProcessing.textContent = "â–¶ Start Real-Time Processing";
  toggleProcessing.classList.remove("primary");
  toggleProcessing.classList.add("secondary");
  setStatus("Real-time processing stopped", "success");
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function setStatus(msg, type = "normal") {
  console.log("[STATUS]", msg);
  statusDiv.textContent = msg;
  statusDiv.className = "status";
  if (type === "error") statusDiv.classList.add("error");
  if (type === "success") statusDiv.classList.add("success");
}

function canvasToBlob(canvas, type = "image/png", quality = 0.92) {
  return new Promise(resolve => {
    canvas.toBlob(blob => resolve(blob), type, quality);
  });
}

function hexToRgbNormalized(hex) {
  let s = hex.trim();
  if (s[0] === "#") s = s.slice(1);
  if (s.length === 3) s = s.split("").map(c => c + c).join("");
  const num = parseInt(s, 16);
  return [
    ((num >> 16) & 255) / 255.0,
    ((num >> 8) & 255) / 255.0,
    (num & 255) / 255.0
  ];
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

window.addEventListener("beforeunload", () => {
  stopRealtimeProcessing();
  if (stream) {
    stream.getTracks().forEach(track => track.stop());
  }
  if (nailRenderer) {
    nailRenderer.destroy();
  }
});
